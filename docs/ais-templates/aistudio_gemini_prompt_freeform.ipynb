{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saxil/ChatBot/blob/ChatBot/docs/ais-templates/aistudio_gemini_prompt_freeform.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2023 Google LLC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKwyTRdwB8aW"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RXInneX6xx7c"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q \"google-generativeai>=0.8.2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "kWIuwKG2_oWE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23dacd95-eb76-47f4-ae55-9d55452194ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "[\n",
            "    {\n",
            "        \"parts\": [\n",
            "            {\n",
            "                \"text\": \"Hello\"\n",
            "            }\n",
            "        ]\n",
            "    }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "# import necessary modules.\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "import base64\n",
        "import json\n",
        "\n",
        "try:\n",
        "    # Mount google drive\n",
        "    from google.colab import drive\n",
        "\n",
        "    drive.mount(\"/gdrive\")\n",
        "\n",
        "    # The SDK will automatically read it from the GOOGLE_API_KEY environment variable.\n",
        "    # In Colab get the key from Colab-secrets (\"ðŸ”‘\" in the left panel).\n",
        "    import os\n",
        "    from google.colab import userdata\n",
        "\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\")\n",
        "except ImportError:\n",
        "    pass\n",
        "\n",
        "# Parse the arguments\n",
        "\n",
        "model = \"gemini-1.5-flash\"  # @param {isTemplate: true}\n",
        "contents_b64 = b'W3sicGFydHMiOiBbeyJ0ZXh0IjogIkhlbGxvIn1dfV0='\n",
        "generation_config_b64 = \"e30=\"  # @param {isTemplate: true}\n",
        "safety_settings_b64 = \"e30=\"  # @param {isTemplate: true}\n",
        "\n",
        "contents = json.loads(base64.b64decode(contents_b64))\n",
        "\n",
        "generation_config = json.loads(base64.b64decode(generation_config_b64))\n",
        "safety_settings = json.loads(base64.b64decode(safety_settings_b64))\n",
        "\n",
        "stream = False\n",
        "\n",
        "print(json.dumps(contents, indent=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7zAD69vE92b"
      },
      "source": [
        "## Original code i got from aistudio.google.com\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "LB2LxPmAB95V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "a014213a-5283-47fc-bdb8-fc154d5b056d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your prompt: hi\n",
            "Hi there! How can I help you today?\n",
            "\n",
            "Enter your prompt: how are you?\n",
            "As a large language model, I don't experience emotions or feelings in the same way humans do. I don't get \"happy\" or \"sad.\" However, I am functioning properly and ready to assist you with your requests. So, I'm doing well and ready to help! How are you?\n",
            "\n",
            "Enter your prompt: exit\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "\n",
        "genai.configure(api_key=\"AIzaSyDdxXOU1yKo_8SRhJ7mzjVdODMl17m6_yk\")\n",
        "\n",
        "# Create the model\n",
        "generation_config = {\n",
        "  \"temperature\": 1,\n",
        "  \"top_p\": 0.95,\n",
        "  \"top_k\": 40,\n",
        "  \"max_output_tokens\": 8192,\n",
        "  \"response_mime_type\": \"text/plain\",\n",
        "\n",
        "}\n",
        "\n",
        "model = genai.GenerativeModel(\n",
        "  model_name=\"gemini-2.0-flash\",\n",
        "  generation_config=generation_config,\n",
        ")\n",
        "\n",
        "chat_session = model.start_chat(\n",
        "  history=[\n",
        "  ]\n",
        ")\n",
        "while True:\n",
        "  prompt=input(\"Enter your prompt: \")\n",
        "  if prompt != \"exit\":\n",
        "    response = chat_session.send_message(prompt)\n",
        "    print(response.text)\n",
        "  else:break"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## code i edited"
      ],
      "metadata": {
        "id": "GJd102s-nOOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as ai\n",
        "import random\n",
        "api_key='AIzaSyDdxXOU1yKo_8SRhJ7mzjVdODMl17m6_yk'\n",
        "ai.configure(api_key=api_key)\n",
        "bot=ai.GenerativeModel(\"gemini-pro\")\n",
        "chat_session = model.start_chat(\n",
        "  history=[\n",
        "  ]\n",
        ")\n",
        "while True:\n",
        "    prompt=input(\"You: \")\n",
        "    response = chat_session.send_message(prompt)\n",
        "    # print(response.text)\n",
        "    # print(\"Bot: \",response.text)\n",
        "    if prompt ==\"bye\":break\n",
        "    elif prompt in [\"What is your name?\",\"Your name?\",\"What should i call you ?\"]:\n",
        "          print(\"Bot: \",[\"It is Lex\",\"You can call me `lex`\",\"i would prefer lex\"][random.randrange(0,2)])\n",
        "    elif prompt in [\"functions\",\"commands\"]:\n",
        "            # response:str = \"As per now i am in my learning state so i cant perform much!\"\n",
        "          print(\"Bot: Here are the functions: \\n -> casual conversation \\n -> Open websites\")\n",
        "    else:\n",
        "      response = chat_session.send_message(prompt).text\n",
        "      print(\"Bot:\",response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "wxkrDyb-jPY8",
        "outputId": "8314a213-ed35-46e6-eaee-9f8719dcbf73"
      },
      "execution_count": 24,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You: hi\n",
            "Hello again! Is there anything specific you'd like to talk about or need help with?\n",
            " You: bye\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c9d345e9868"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://ai.google.dev/gemini-api/docs\"><img src=\"https://ai.google.dev/static/site-assets/images/docs/notebook-site-button.png\" height=\"32\" width=\"32\" />Docs on ai.google.dev</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/google-gemini/cookbook/blob/main/quickstarts\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />More notebooks in the Cookbook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Tce3stUlHN0L"
      ],
      "name": "aistudio_gemini_prompt_freeform_nofiles.ipynb",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}