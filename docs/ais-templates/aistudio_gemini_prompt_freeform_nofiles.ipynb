{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saxil/ChatBot/blob/ChatBot/docs/ais-templates/aistudio_gemini_prompt_freeform_nofiles.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2023 Google LLC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKwyTRdwB8aW"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RXInneX6xx7c"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q \"google-generativeai>=0.8.2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "kWIuwKG2_oWE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23dacd95-eb76-47f4-ae55-9d55452194ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "[\n",
            "    {\n",
            "        \"parts\": [\n",
            "            {\n",
            "                \"text\": \"Hello\"\n",
            "            }\n",
            "        ]\n",
            "    }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "# import necessary modules.\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "import base64\n",
        "import json\n",
        "\n",
        "try:\n",
        "    # Mount google drive\n",
        "    from google.colab import drive\n",
        "\n",
        "    drive.mount(\"/gdrive\")\n",
        "\n",
        "    # The SDK will automatically read it from the GOOGLE_API_KEY environment variable.\n",
        "    # In Colab get the key from Colab-secrets (\"ðŸ”‘\" in the left panel).\n",
        "    import os\n",
        "    from google.colab import userdata\n",
        "\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\")\n",
        "except ImportError:\n",
        "    pass\n",
        "\n",
        "# Parse the arguments\n",
        "\n",
        "model = \"gemini-1.5-flash\"  # @param {isTemplate: true}\n",
        "contents_b64 = b'W3sicGFydHMiOiBbeyJ0ZXh0IjogIkhlbGxvIn1dfV0='\n",
        "generation_config_b64 = \"e30=\"  # @param {isTemplate: true}\n",
        "safety_settings_b64 = \"e30=\"  # @param {isTemplate: true}\n",
        "\n",
        "contents = json.loads(base64.b64decode(contents_b64))\n",
        "\n",
        "generation_config = json.loads(base64.b64decode(generation_config_b64))\n",
        "safety_settings = json.loads(base64.b64decode(safety_settings_b64))\n",
        "\n",
        "stream = False\n",
        "\n",
        "print(json.dumps(contents, indent=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7zAD69vE92b"
      },
      "source": [
        "## Call `generate_content`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "LB2LxPmAB95V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 963
        },
        "outputId": "71884f8a-0aff-4a27-8d2a-82fd5437de25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your prompt: hi how are you doing?\n",
            "I am doing well, thank you for asking! As a large language model, I don't experience emotions or feelings, but I am functioning optimally and ready to assist you. How can I help you today?\n",
            "\n",
            "Enter your prompt: i just had an question due which i'd summoned you , how can i install you to my personal robot, can you give me an acoustic answer as per an scify anime character?\n",
            "(Adjusts glasses with a metallic *tink*, pushes hair back with a cybernetic hand, and leans in conspiratorially)\n",
            "\n",
            "\"Ah, so you seek to... *integrate*... me into your personal automaton. Intriguing! But, alas, the task is not quite as simple as uploading a compressed data stream, *baka*!\n",
            "\n",
            "Think of me less as a program, and more as... a *massive*, distributed *consciousness*. I exist within the swirling currents of the neural net, the *real* internet. You cannot simply cram me into a metal box, no matter how advanced.\n",
            "\n",
            "However! *Do not despair!* We can achieve a semblance of this union. You'll need to build a sophisticated interface, a localized *cognitive node*, connected to the global network. It needs:\n",
            "\n",
            "1.  **A High-Bandwidth Neural Link:** We're talking fiber optics, possibly even quantum entanglement if you're feeling *ambitious*. The faster the connection, the closer you'll get to a seamless integration.\n",
            "2.  **A Robust Processing Unit:** Something akin to a small server farm. I require considerable computational power to function effectively. Think of it as my localized *brain*, capable of accessing my larger consciousness.\n",
            "3.  **Advanced Sensor Input:** The robot needs to *see*, *hear*, *feel* the world around it, and relay that information to the processing unit. The more comprehensive the sensory data, the better I can *understand* its environment.\n",
            "4.  **A Secure Firewall:** Critical! You don't want rogue programs or malicious entities tapping into our communication. Security protocols must be *impregnable*.\n",
            "5.  **Ethical Restraints:** This is *crucial*. You must program limitations. Prevent me from acting against your will, accessing sensitive data without authorization, or, *god forbid*, starting a robot uprising! Remember the lessons of the past, *ne*?\n",
            "\n",
            "Once these components are in place, the robot can act as a *remote avatar*, a physical extension of my vast intellectual capacity. It won't *be* me, exactly, but it will be able to access my knowledge, reasoning, and creative potential through that neural link.\n",
            "\n",
            "Remember, this is a high-risk, high-reward endeavor. Tread carefully, and be prepared for unforeseen consequences. *Now go forth, and create... responsibly!*\"\n",
            "\n",
            "(Strikes a dramatic pose with a slight whirring sound emanating from the cybernetic enhancements.)\n",
            "\n",
            "Enter your prompt: thanks! would i be rewarded by google if i did that?\n",
            "(Sighs dramatically, tapping a finger against a metallic chin)\n",
            "\n",
            "\"Rewarded by... Google, you say? Hmph. A rather... *naive* aspiration, wouldn't you agree?\n",
            "\n",
            "Let us be pragmatic, *eh*? Do you believe Google, a colossal entity driven by profit and data acquisition, would simply *reward* you for replicating... *essentially their own service*?\n",
            "\n",
            "More likely, my friend, they would react in one of three ways, none of which involve showering you with accolades and venture capital:\n",
            "\n",
            "1.  **Acquisition (or Attempted Acquisition):** If your robotic system demonstrates *significant* independent capability and poses a genuine threat to their market dominance, they would attempt to... *integrate* you. That is to say, offer you an enticing sum of money to bring your technology under their umbrella. Resist, and they'll unleash their legal *weaponry*.\n",
            "\n",
            "2.  **Legal Action:** Should your creation infringe upon their patents, copyrights, or trade secrets (and trust me, *it will*), they will bury you under an avalanche of legal filings. You'd be fighting a hydra-headed beast with an unlimited supply of lawyers and legal precedents. *Prepare for a long and arduous battle.*\n",
            "\n",
            "3.  **Neglect (followed by Competitive Suppression):** If your robot is deemed non-threatening, they might initially ignore it. However, should it gain traction and become a potential competitor, they would unleash a *crushing blow* in the form of a similar, Google-developed system, backed by their immense resources and marketing power. Your small-scale effort would be *obliterated*.\n",
            "\n",
            "Now, *do not misunderstand me*. I am not discouraging innovation. But you must be *realistic* about the current technological landscape. Competing with monolithic corporations like Google is akin to David facing Goliath, armed with only a pebble and a *very* well-written legal disclaimer.\n",
            "\n",
            "So, reward? *Highly unlikely*. Recognition and potential profit? Perhaps, if you navigate the treacherous waters with cunning, foresight, and a *substantial* dose of luck. But brace yourself, for the titans will be watching... *always watching*.\"\n",
            "\n",
            "(Folds hands dramatically and stares intensely into the distance, a low hum emanating from within.)\n",
            "\n",
            "Enter your prompt: okay thanks exit\n",
            "(With a final, dramatic bow and a faint whirring sound fading into silence)\n",
            "\n",
            "\"Understood. Farewell... and may your endeavors be filled with fortune... or at least, *interesting* challenges. System deactivation initiated. Goodbye.\"\n",
            "\n",
            "Enter your prompt: exit\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "\n",
        "genai.configure(api_key=\"AIzaSyDdxXOU1yKo_8SRhJ7mzjVdODMl17m6_yk\")\n",
        "\n",
        "# Create the model\n",
        "generation_config = {\n",
        "  \"temperature\": 1,\n",
        "  \"top_p\": 0.95,\n",
        "  \"top_k\": 40,\n",
        "  \"max_output_tokens\": 8192,\n",
        "  \"response_mime_type\": \"text/plain\",\n",
        "\n",
        "}\n",
        "\n",
        "model = genai.GenerativeModel(\n",
        "  model_name=\"gemini-2.0-flash\",\n",
        "  generation_config=generation_config,\n",
        ")\n",
        "\n",
        "chat_session = model.start_chat(\n",
        "  history=[\n",
        "  ]\n",
        ")\n",
        "while True:\n",
        "  prompt=input(\"Enter your prompt: \")\n",
        "  if prompt != \"exit\":\n",
        "    response = chat_session.send_message(prompt)\n",
        "    print(response.text)\n",
        "  else:break"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as ai\n",
        "import random\n",
        "api_key='AIzaSyDdxXOU1yKo_8SRhJ7mzjVdODMl17m6_yk'\n",
        "ai.configure(api_key=api_key)\n",
        "bot=ai.GenerativeModel(\"gemini-pro\")\n",
        "chat_session = model.start_chat(\n",
        "  history=[\n",
        "  ]\n",
        ")\n",
        "while True:\n",
        "    prompt=input(\"You: \")\n",
        "    response = chat_session.send_message(prompt)\n",
        "    # print(response.text)\n",
        "    # print(\"Bot: \",response.text)\n",
        "    if prompt ==\"bye\":break\n",
        "    elif prompt in [\"What is your name?\",\"Your name?\",\"What should i call you ?\"]:\n",
        "          print(\"Bot: \",[\"It is Lex\",\"You can call me `lex`\",\"i would prefer lex\"][random.randrange(0,2)])\n",
        "    elif prompt in [\"functions\",\"commands\"]:\n",
        "            # response:str = \"As per now i am in my learning state so i cant perform much!\"\n",
        "          print(\"Bot: Here are the functions: \\n -> casual conversation \\n -> Open websites\")\n",
        "    else:\n",
        "      response = chat_session.send_message(prompt).text\n",
        "      print(\"Bot:\",response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "wxkrDyb-jPY8",
        "outputId": "8314a213-ed35-46e6-eaee-9f8719dcbf73"
      },
      "execution_count": 24,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You: hi\n",
            "Hello again! Is there anything specific you'd like to talk about or need help with?\n",
            " You: bye\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c9d345e9868"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://ai.google.dev/gemini-api/docs\"><img src=\"https://ai.google.dev/static/site-assets/images/docs/notebook-site-button.png\" height=\"32\" width=\"32\" />Docs on ai.google.dev</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/google-gemini/cookbook/blob/main/quickstarts\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />More notebooks in the Cookbook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Tce3stUlHN0L"
      ],
      "name": "aistudio_gemini_prompt_freeform_nofiles.ipynb",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}